{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "251fc290",
   "metadata": {},
   "source": [
    "## Exercise 1: Do you remember how to check python version and installed libraries? Write steps below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0995af97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.8\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print (python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2222cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"tutorialspoint.com is the process of breaking down text document apart into those pieces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "553e9d58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tutorialspoint',\n",
       " 'com',\n",
       " 'is',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'breaking',\n",
       " 'down',\n",
       " 'text',\n",
       " 'document',\n",
       " 'apart',\n",
       " 'into',\n",
       " 'those',\n",
       " 'pieces']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim as gs\n",
    "toknizedword = list(gs.utils.tokenize(document))\n",
    "toknizedword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce30dd74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(gs.utils.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a73fe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 3), (26, 1), (27, 1), (28, 1), (29, 3), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 2), (44, 2), (45, 1)]]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from pprint import pprint \n",
    "text = [\"\"\" In computer science, artificial \n",
    "intelligence (AI), sometimes called machine \n",
    "intelligence, is intelligence demonstrated by \n",
    "machines, in contrast to the natural intelligence \n",
    "displayed by humans and animals. Computer science \n",
    "defines AI research as the study of intelligent \n",
    "agents: any device that perceives its environment and \n",
    "takes actions that maximize its chance of successfully \n",
    "achieving its goals.\"\"\" ] \n",
    "tokens = [[token for token in sentence.split()] for sentence\n",
    "in text] \n",
    "gensim_dictionary = corpora.Dictionary() \n",
    "gensim_corpus = [gensim_dictionary.doc2bow(token, \n",
    "allow_update=True) for token in tokens] \n",
    "print(gensim_corpus) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520fcb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frquencises = [[(gensim_dictionary[id], frequence) for id, frequence in couple]for couple in genism_corpus]\n",
    "                   print(word_frquencises)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ceafe",
   "metadata": {},
   "source": [
    "# Create a bag of words corpus by reading a text file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8732f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pprint\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "005d0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = [\n",
    "    \"tutorialspoint.com is the process of breaking down text document apart into those pieces\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4861ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = [simple_preprocess(doc) for doc in doc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a215b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b33f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW_corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in doc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25cf1f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(BoW_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1f31b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
